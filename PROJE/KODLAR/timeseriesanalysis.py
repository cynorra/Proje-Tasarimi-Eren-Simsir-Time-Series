# VERI SETI: https://www.tcmb.gov.tr/wps/wcm/connect/TR/TCMB+TR/Main+Menu/Istatistikler/Enflasyon+Verileri/Tuketici+Fiyatlari
# EVDS API kullanilmistir

import warnings
warnings.filterwarnings("ignore")

import pandas as pd
import evds as ev
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

from arch.unitroot import ADF,PhillipsPerron,KPSS,ZivotAndrews # birim kok testi

from scipy.stats import boxcox

from statsmodels.graphics.tsaplots import month_plot, plot_acf
import statsmodels.api as sm


from merlion.models.utils.autosarima_utils import nsdiffs


from sklearn.preprocessing import PolynomialFeatures
from scipy.special import inv_boxcox  # boxcox'i tersine Ã§evirmek iÃ§in


from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error


from statsmodels.tsa.holtwinters import Holt, ExponentialSmoothing

from pmdarima import auto_arima
from statsmodels.tsa.statespace.sarimax import SARIMAX

from statsmodels.stats.diagnostic import acorr_ljungbox, het_arch, acorr_breusch_godfrey

from statsmodels.tsa.x13 import x13_arima_select_order # normal order ve seasonal order yapilarini ortaya Ã§ikartir.
import os

from statsmodels.tsa.seasonal import seasonal_decompose

from scipy.stats import ttest_1samp, jarque_bera
from arch import arch_model

## iyilestirmeler - 13.12.24

from statsmodels.tsa.stattools import adfuller
import ruptures as rpt



api = "5Nca6TRSIR"
    
evds = ev.evdsAPI(api)

tufe = evds.get_data(["TP.FG.J0"],startdate="01-01-2003",enddate="01-02-2025",frequency=5)
tufe.rename(columns={"TP_FG_J0":"TUFE"},inplace=True) # veri seti duzenleme



tarih=pd.date_range("01-01-2003",periods=len(tufe),freq="M") # tarih indekslemek iÃ§in
tufe["Tarih"]=tarih
tufe.set_index("Tarih",inplace=True) # aylik indeksleme yaptik - evds api freq 5 => aylik


'''
df = tufe.resample("Y").mean() # yillik ortalama tufe (tuketici fiyatlari)
df.index = df.index.year


sns.heatmap(df,annot=True,fmt=".2f",cmap="Reds")
plt.show()

# tufe degerlerinden enflasyon hesaplamasi yapilcak ( veri islenecek )


tufe["Enflasyon"] = tufe.pct_change()*100 # aylik enflasyon
print(tufe)
'''

enfay = tufe.pct_change() * 100
enfay.dropna(inplace=True)
enfay = pd.DataFrame(enfay)
enfay.rename(columns={"TUFE":"Enf"},inplace=True)

'''
plt.plot(tufe)
plt.show()
'''


adf = ADF(tufe,trend="ct")
pp = PhillipsPerron(tufe,trend="ct")
kpss = KPSS(tufe,trend="ct")

#print(adf) # regresyon analizi yapiyor - test statistic - p value ve lags degerleri cikiyor
#print(pp)
#print(kpss)


# p value -> h0 testi 1 veya 0 || 0 ise h0 reddedilir duragandir.



###################### 13.12.24 Ä°yilestirme

# DuraganlÄ±k Testi Ä°cin Fonksiyonlar ADF ve PP

def adf_test(series):
    """
    ADF testi uygular ve sonucu dÃ¶ndÃ¼rÃ¼r.
    """
    result = adfuller(series, autolag="AIC")
    return {
        "Test StatistiÄŸi": result[0],
        "p-deÄŸeri": result[1],
        "Kritik DeÄŸerler": result[4],
        "Duragan mÄ±?": "Evet" if result[1] < 0.05 else "HayÄ±r"
    }

def pp_test(series):
    """
    Phillips-Perron testi uygular ve sonucu dÃ¶ndÃ¼rÃ¼r.
    """
    result = PhillipsPerron(series)
    return {
        "Test StatistiÄŸi": result.stat,
        "p-deÄŸeri": result.pvalue,
        "Duragan mÄ±?": "Evet" if result.pvalue < 0.05 else "HayÄ±r"
    }


##

## duraganlÄ±k icin uygulama
def duraganlik_uygula(data):
    """
    ADF ve PP testlerini uygular ve sonuÃ§larÄ± bir DataFrame'de toplar.
    """
    adf_results = adf_test(data)
    pp_results = pp_test(data)
    
    results = pd.DataFrame({
        "Test": ["ADF", "PP"],
        "Test StatistiÄŸi": [
            adf_results["Test StatistiÄŸi"],
            pp_results["Test StatistiÄŸi"]
        ],
        "p-deÄŸeri": [
            adf_results["p-deÄŸeri"],
            pp_results["p-deÄŸeri"]
        ],
        "Duragan mÄ±?": [
            adf_results["Duragan mÄ±?"],
            pp_results["Duragan mÄ±?"]
        ]
    })
    return results

# Testleri Ã§alÄ±ÅŸtÄ±rma
duraganlik_sonuclari = duraganlik_uygula(tufe["TUFE"])
print(duraganlik_sonuclari)


####### YapÄ±sal KÄ±rÄ±lma Analizi - Ruptures Kutuphanesi


def yapisal_kirilma_testi(series):
    """
    YapÄ±sal kÄ±rÄ±lma analizi yapar ve kÄ±rÄ±lma noktalarÄ±nÄ± dÃ¶ndÃ¼rÃ¼r.
    """
    algo = rpt.Binseg(model="l2").fit(series.values)
    breakpoints = algo.predict(n_bkps=5)
    return breakpoints

def plot_structural_breaks(series, breakpoints):
    """
    YapÄ±sal kÄ±rÄ±lmalarÄ± gÃ¶rselleÅŸtirir plotlar.
    """
    rpt.display(series.values, breakpoints)
    plt.title("YapÄ±sal KÄ±rÄ±lmalar")
    plt.show()

# KÄ±rÄ±lma analizi ve gÃ¶rselleÅŸtirme
breakpoints = yapisal_kirilma_testi(tufe["TUFE"])
plot_structural_breaks(tufe["TUFE"], breakpoints)


############# 13.12.24 iyilestirme sonu ############################





####### yapisal kirilma testi
# c - sabit - ct sabit trendi - t direkt trend

#print('yapisal kirilma')

trend = ["c","ct","t"] # yapisal kirilma olabilir mi ?

for i in trend:
    z = ZivotAndrews(tufe,trend=i)
    #print(z)

# h0 'i reddedemedigimiz icin (duragan bulamadigimiz icin) yapisal kirilma (anlamli) yok. - p value 1 ciktigindan h1 reddedilir.

tufe_train = tufe.iloc[:36]
tufe_test = tufe.iloc[-36:]
#print(tufe_test)


# boxcox

tufe_train_bx,lm = boxcox(tufe_train["TUFE"])
tufe_train["Box-Cox"] = tufe_train_bx

'''
print(tufe_train)
# regresyon modelinde deterministik trend anlamli cikti.
'''

# - - - -

# GUNCELLEME 15.12.24

# DaÄŸÄ±lÄ±m gÃ¶rselleÅŸtirme
fig, ax = plt.subplots(1, 2, figsize=(12, 6))
sns.histplot(tufe["TUFE"], kde=True, ax=ax[0])
ax[0].set_title("Box-Cox Ã–ncesi DaÄŸÄ±lÄ±m")
sns.histplot(tufe_train["Box-Cox"], kde=True, ax=ax[1])
ax[1].set_title("Box-Cox SonrasÄ± DaÄŸÄ±lÄ±m")
plt.tight_layout()
plt.show()

## GUNCELLEME SONU

tufe_train["Aylar"] = tufe_train.index.month
dummy=pd.get_dummies(tufe_train["Aylar"],prefix="Aylar",dtype=int,drop_first=False) #kukla degiskenlere Ã§evrilerek regresyon modeli olusturulur. Aylar degeri 2 ise Aylar_2 gibi sutun degiskeni olusturur. Kolaylik saglar.
tufe_train=pd.concat([tufe_train,dummy],axis=1)

########## stats models

x = tufe_train.drop(columns=["TUFE","Box-Cox","Aylar"])
y = tufe_train["TUFE"]
model = sm.OLS(y,x).fit() # stat models regression linear model OLS
# print(model.summary())
# mevsimsellik bir deterministik yok,




########## stokastik mevsimsellik kontrol - merlion

a = nsdiffs(tufe_train["Box-Cox"],m=12,test="ch")
b = nsdiffs(tufe_train["Box-Cox"],m=12,test="ocsb")

#print(a)
#print(b)



########## indeksleme | regresyon modelleme yapabilmek iÃ§in

indeks = np.arange(1,len(tufe_train)+1)
tufe_train["T"] = indeks


x = sm.add_constant(tufe_train["T"])
y = tufe_train["Box-Cox"]

# model testing
model = sm.OLS(y,x).fit()
# print(model.summary())


pol = PolynomialFeatures(degree=3)
xp = pol.fit_transform(tufe_train["T"].values.reshape(-1,1))


# model testing
model = sm.OLS(y,xp).fit()
# print(model.summary())
# Durbin Watson degeri artmasina ragmen p degeri artti



#
girdi = np.arange(len(tufe_train.index)+1,len(tufe_train.index)+37)
tahmin = model.predict(pol.fit_transform(girdi.reshape(-1, 1)))
tahmin = inv_boxcox(tahmin,lm) # yukarda kullandigimiz lambda degerini gonderdik
tufe_test["Tahmin"] = tahmin   # duragan olmadigi iÃ§in sahte regresyonlarla Ã§ok verimli islem yapamiyoruz.
# print(tufe_test) # TUFE degerleriyle Tahmin degerlerimiz arasinda ciddi fark var - anlamsiz.

# print(r2_score(tufe_test["TUFE"],tufe_test["Tahmin"]))  # r2 score degeri -5.23 geldi
# egitimde %99 luk basari olmasina ragmen testlerde durum kotu. 
# duraganlik oldugunu gosteriyor.
# r2 yapisi sahte regresyon oldugunu anlayabiliyoruz.



############################ USTEL DUZELTMELER

##### HOLT MODEL
# HOLT model RMSE = 1468.83




model = Holt(tufe_train["Box-Cox"]).fit(optimized=True) 
tahmin = model.forecast(36) # 36 test verisi
tahmin = inv_boxcox(tahmin,lm) # boxcox donusumu

# print(r2_score(tufe_test["TUFE"],tahmin))  # -5.2680
# print(np.sqrt(mean_squared_error(tufe_test["TUFE"],tahmin))) # HOLT model RMSE = 1468.83



##### HOLT WINTERS MODEL
# HOLT WINTERS model RMSE min 1471 Ã§ikti.


# Ã§arpimsal ve toplamsal olarak tiplere bakilacak
# seride 0 deger varsa sifirlayacagindan normalde sikinti Ã§ikartabilen bir model.


trend_tip = ["add","mul"]
seas_tip = ["add","mul"]
per = range(2,13) # periyot - mevsimsellik kalibi


sonuc = pd.DataFrame(columns=["Trend","Mevsimsellik","Periyod","R2","RMSE"])

for i in trend_tip:
    for j in seas_tip:
        for k in per:
            model = ExponentialSmoothing(tufe_train["Box-Cox"],trend=i,seasonal=j,seasonal_periods=k).fit(optimized=True)
            tahmin = model.forecast(36) # 36 veri iÃ§in
            tahmin = inv_boxcox(tahmin,lm)
            rmse = np.sqrt(mean_squared_error(tufe_test["TUFE"],tahmin))
            sonuc = sonuc._append({"Trend":i,"Mevsimsellik":j,"Periyod":k,"RMSE:":rmse},ignore_index=True)

sonuc = sonuc.sort_values(by="RMSE") # sutun adina gore df'yi sortla
# print(sonuc)  minimum RMSE 1471 Ã§ikti.




##### ARIMA

model = auto_arima(tufe_train["Box-Cox"],seasonal=False,trace=False)
# print(model.summary())
# AIC -> -130
# SARIMAX(2, 1, 1) kullanildi

# seasonal yapisi kullanilarak

sonuc = pd.DataFrame(columns=["m","AIC"])

for i in range(2,13):
    model = auto_arima(tufe_train["Box-Cox"],seasonal=True,trace=False,m=i)
    sonuc = sonuc._append({"m":i,"AIC":model.aic()},ignore_index=True)

sonuc = sonuc.sort_values(by="AIC")
# print(sonuc)




##### SARIMAX

model = SARIMAX(tufe_train["Box-Cox"],order=(0,1,1),seasonal_order=(2,0,1,12),trend="c").fit()
# ma.l1 0 ise problem yok, 0'dan buyuk degerler icin problemdir
# order parametresinde buna dikkat edicez
# model summary kisminda Model:SARIMAX(0,1,2)x(2,..) gibi devam eden kisimda
# L1'de sikinti olmadigi iÃ§in SARIMAX'in 0,1 degerlerini aldik.
# 2'yi 1'e indirdik ma.l2 1'den buyuk sikintili oldugu icin
# z ve P>|z| degerlerine bakarak cevap verdik.
# intercept yapisinda oldugundan trend="c" (constant-sabit) parametresi ekledik


# print(model.summary())
# AIC -> -120
# SARIMAX(0, 1, 1)



################# ARIMA KULLANILACAK
# oto korelasyon olmayacak
# arch etkisi olmayacak

# q model
q = acorr_ljungbox(model.resid)
h = het_arch(model.resid,nlags=1,ddof=3)[1] # modeli egitirken 3 parametre kullandigimiz iÃ§in
# serbestlik derecesi ddof 3 oldu.

# print(q)
# print(h)



####### seasonal order kullanimi

# model = SARIMAX(tufe_train["Box-Cox"],order = (0,1,1), seasonal_order=(1,0,1,12),trend="n").fit()

# path = r'C:\WinX13\x13as'
# arima = x13_arima_select_order(tufe_train["Box-Cox"],x12path = path, outlier=True)
# outlier - aykiri gozlem varsa dikkate alir

# print(arima.order) # order (1,1,0)
# print(arima.sorder)  # seasonal order (0,1,1,12)



#########

enfay = tufe["TUFE"].pct_change() * 100
enfay.dropna(inplace=True)
enfay = pd.DataFrame(enfay)
enfay.rename(columns={"TUFE":"Enf"},inplace = True)

enf_train = enfay.iloc[:-36]
enf_test = enfay.iloc[-36:]

# mevsimsel duzeltme - seasonal decompose
ayris = seasonal_decompose(enf_train["Enf"],model="add", period = 12, extrapolate_trend = "freq")
# ayris.plot()
# plt.show()

veri = pd.concat([
    ayris.observed,
    ayris.trend,
    ayris.seasonal,
    ayris.observed - ayris.seasonal, # toplamsal model kullandigimiz icin / yerine Ã§ikartma yaptik
    ayris.resid],axis=1)        # resid -> rassal


veri.columns = ["Enf","Trend","Mevsimsellik","Mevsimsel Duzeltme","Rassal"]

# y = mevsimsellik + rassal + trend -> Enflasyon

# plt.plot(veri["Mevsimsel Duzeltme"])
# plt.show()

# mevsimsel duzeltmenin dogrusallikla bir korelasyonu var mi ona bakicaz

indeks = np.arange(1,len(veri)+1) # dogrusallik yapisi (girdi olarak kullanilacakti - linear regression)
# print(indeks)
# plt.plot(indeks)
# plt.show()

# yukari yonluyse (hatasi dusukse) yuksek r'2 degeri Ã§ikar ve dogrusal korelasyon vardir.
# numpy korelasyon matrisini kullanalim

# print(np.corrcoef(veri["Mevsimsel Duzeltme"],indeks))
# 0.21 'lik korelasyon Ã§ikti. -(linear degil)
# verimizde deterministik bir mevsimsellik var
# mevsimselligi dislayip mevsimsel duzeltme katsayisina ulastik.
# mevsimsel duzeltmeyi dogru modelleyebilirsek deterministik oldugu iÃ§in ekleme yapip tahmin sonucu elde edebiliriz.
# mevsimsellik yapisinda trend yapisi olmadigi iÃ§in dogrusal model yapisi kuramadik - kuramayiz.

# mevsimsel olmayan arima modeliyle devam edicez

model = auto_arima(veri["Mevsimsel Duzeltme"],seasonal = False, Trace = False)
# print(model.summary()) 
# AIC 458
# arch etkisi - (geriye kalan artiklar uzerinden kontrol edicez) ve otokorelasyon var mi ?


##### oto korelasyon
# ac = acorr_ljungbox(model.resid()) # rassal degerler

### arch etkisi
# h = het_arch(model.resid(), nlags = 1 , ddof=3)[1] # serbestlik derecesi ddof = 3 ( p + d )

# print(ac)  # anlamli korelasyon yok
# print(h) # 0.001 arch etkisi var.

enf_test["Mevsimsellik"] = veri["Mevsimsellik"].iloc[-36:].values
tahmin = model.predict(36)
enf_test["Tahmin"] = tahmin + enf_test["Mevsimsellik"]
# print(enf_test)
# enflasyonla tahmin degerleri arasinda Ã§ok fark var
# bunun nedeni arch etkisinden dolayi,

## mevsimsel duzeltmeyi kullanmicaz, sarima kullanicaz.

'''
for i in range(2,13):
    model = auto_arima(veri["Enf"],seasonal=True,m=i,trace=False)
    print("m:{} Aic: {}".format(i,model.aic()))
'''

'''
m:2 Aic: 515.2326035115791
m:3 Aic: 509.77785147828354
m:4 Aic: 502.2720704046204
m:5 Aic: 541.3718499213408
m:6 Aic: 509.2182209465135
m:7 Aic: 541.3718499213408
m:8 Aic: 518.7257272095954
m:9 Aic: 528.3586976084922
m:10 Aic: 541.3718499213408
m:11 Aic: 541.3718499213408
m:12 Aic: 494.3792266831782

Bu modelde Aic degeri oncekine gore yuksek Ã§ikti, kullanmayacagiz.
'''


# Yumusatma ustel Modelleri Deneyelim:
    
sonuc = pd.DataFrame(columns=["Donem", "RMSE"])
period = range(2,13)

# hold winters mevsimselligi de baz aliyor

for i in period:
    model = ExponentialSmoothing(enf_train["Enf"],trend="add",seasonal="add",seasonal_periods=i).fit(optimized=True)
    tahmin = model.forecast(36) # 36 donemlik
    rmse = np.sqrt(mean_squared_error(enf_test["Enf"], tahmin))
    sonuc = sonuc._append({"Donem":i,"RMSE":rmse},ignore_index=True)
    
    
sonuc = sonuc.sort_values(by="RMSE") # kucukten buyuge
# print(sonuc)

'''
    Donem      RMSE
1     3.0  3.904438
7     9.0  3.912075
0     2.0  3.933386
8    10.0  3.934485
6     8.0  3.948194
9    11.0  3.949118
10   12.0  3.970932
4     6.0  3.997553
2     4.0  4.140709
3     5.0  4.206096
5     7.0  4.227467

Periyot olarak 3 donem kullandigimizda en dusuk RMSE degerine ulasabiliyoruz
Deneyelim:
'''


model = ExponentialSmoothing(enf_train["Enf"],trend="add",seasonal="add",seasonal_periods=3).fit(optimized=True)
tahmin = model.forecast(36) # 36 donemlik
enf_test["Tahmin"] = tahmin
# print(enf_test)
    
    
sonuc = sonuc.sort_values(by="RMSE")
# print(sonuc)

'''
Donem      RMSE
0     3.0  3.904438
19   10.0  3.904438
18    9.0  3.904438
17    8.0  3.904438
16    7.0  3.904438
15    6.0  3.904438
14    5.0  3.904438
13    4.0  3.904438
12    3.0  3.904438
11    2.0  3.904438
21   12.0  3.904438
20   11.0  3.904438
1     9.0  3.912075
2     2.0  3.933386
3    10.0  3.934485
4     8.0  3.948194
5    11.0  3.949118
6    12.0  3.970932
7     6.0  3.997553
8     4.0  4.140709
9     5.0  4.206096
10    7.0  4.227467
'''

# mevsimsel duzeltme = trend + rassal oldugundan rassal'lik enflasyona ciddi etkisi var.
# sabir bir ortalama modeliyle tahmin etmek zordur
# -----------------

### veri gorsellestirelim

veri.plot(y=["Enf","Trend","Rassal"])
#plt.show()

# enflasyon rassal soklarla hareket ediyor.
# trend veya rassali tek basina modelleyebilir miyiz ?

# trend -> belirli bir ortalama etrafinda gidiyor - linear regresyonla aÃ§iklanmaz
# mevsimsellik -> deterministiktir.
# rassallik -> bunun uzerinde durucaz.


indeks = np.arange(1,len(veri)+1)
veri["T"] = indeks

# polinomal regresyonla

pol = PolynomialFeatures(degree = 3)
xp = pol.fit_transform(veri["T"].values.reshape(-1,1))

y = veri["Trend"]
model = sm.OLS(y,xp).fit()
# print(model.summary())

# Log - Likehood = Katsayilar Anlamli
# Prob (F-statistic) > 0 : Model Anlamli
# R^2 dusuk Ã§unku dogrusal model degil.

tahmin = model.predict(xp)

# sns.scatterplot(x = veri["T"], y=veri["Trend"], label="GerÃ§ek Degerler")
# sns.lineplot(x = veri["T"], y=tahmin, label="Tahmin")
# plt.show()

#print(model.summary()) # polinom derecesi 1 'ken R^2 0.35
                       # polinom derecesi 2 'ken R^2 0.595
                       # polinom derecesi 3 'ken R^2 0.630


## modelin artiklari
artik = model.resid

## plot acf - otokoralasyon yapisi
#plot_acf(artik, zero=False)
#plt.show()


# acorr_breusch_godfrey - artiklarin otokoralasyonunu test edicek
h = acorr_breusch_godfrey(model)[1] # h1 - otokoralasyonun var oldugunu | h
# prop degeri onemli oldugundan modelin [1] degerini aldik.

# print(h) - 5.5162208818113e-40  - h1 kabul (h>0)


######### ARIMA ile Trendi tahmin etme
# trend modeli

model = auto_arima(veri["Trend"],seasonal = False, trace= False)
# print(model.summary())
# ar degerleri yok, (mevsimsellik kontrol edilmedi)

artik = model.resid()
ac = acorr_ljungbox(artik)
# print(ac) # otokoralasyon testi - anlamli degil.

# arch etkisi testi
h = het_arch(artik, nlags=1, ddof=3)[1]
# print(h) 0.9953081082332432 - p-degeri > 0.05 || 0.99 > 0.05 H0 kabul (arch etkisi yok)


#### tahmin
tahmin = model.predict_in_sample()
# print('TAHMIN:')
# print(tahmin)

# plt.plot(veri["Trend"],label="Trend")
# plt.plot(tahmin,label = "Tahmin")
# plt.legend()
# plt.show()



####### Rassal Hareket Analizi
## Ozetle
# Deterministik Mevsimsellik var
# Trend -> arch etkisi yok , otokorelasyon yapisi yok.
# Rassal'in Enflasyona etkisi en fazla derecede.
# ttest ile


# rassalligin ortalamasi sifir mi fark li mi ?

t_ist,p = ttest_1samp(veri["Rassal"], popmean=0)
# popmean -> hangi degerden farkli olup olmadigini test etmek icin verdigimiz deger
# print(p)
# 0.9255763888159445   -   h0 kabul arima yerine zero modeli secilebilir ( 0 ortalamaya sahip )


#### ADF augmented dickey fuller Testi - Rassal
# ortalama 0 oldugu icin trend n gonderebiliriz

adf = ADF(veri["Rassal"],trend="n")
# print(adf)

'''
Test Statistic: -8
Trend: No Trend
Critical Values: -2.58 (1%), -1.94 (5%), -1.62 (10%)
Null Hypothesis: The process contains a unit root.
'''


#### PhillipsPerron
pp = PhillipsPerron(veri["Rassal"],trend="n")
## print(pp)

'''
Test Statistic                -16.056
P-value                         0.000
Lags                               15
-------------------------------------

Trend: No Trend
Critical Values: -2.58 (1%), -1.94 (5%), -1.62 (10%)
Null Hypothesis: The process contains a unit root.
'''


###

sns.histplot(veri["Rassal"],kde=True)
# plt.show()
# kde - normal dagilim


##### normallik testi

n = jarque_bera(veri["Rassal"]) # normal dagilima uymamasini bekliyoruz..
# h0 normal dagilir
# h1 normal dagilmaz

# print(n)
# SignificanceResult(statistic=1076.5207353062297, pvalue=1.723822325527858e-234)
# normal dagilim yok
# seri duragan



#### ARCH ile modelleyecegiz

p_val = range(1,5) # 5 i kapsamayacagi icin max 4 gecikme denemesi
q_val = range(1,5)
o_val = range(0,2)

dag = ["ged","normal","studentst","skewt"]
model = ["GARCH","EGARCH"]

sonuc = pd.DataFrame(columns=["p","o","q","Model","Dagilim","Aic"])

for p in p_val:
    for q in q_val:
        for o in o_val:
            for d in dag:
                for m in model:
                    modelarch = arch_model(veri["Rassal"],p=p,o=o,q=q,vol=m,dist=d,mean="Zero").fit(disp="off")
                    sonuc = sonuc._append({"p":p,"o":o,"q":q,"Model":m,"Dagilim":d,"Aic":modelarch.aic},ignore_index=True)

sonuc = sonuc.sort_values(by="Aic")

# print(sonuc)

'''

p  o  q   Model Dagilim         Aic
14   1  1  1   GARCH   skewt  381.491804
30   1  1  2   GARCH   skewt  383.491803
78   2  1  1   GARCH   skewt  383.491804
142  3  1  1   GARCH   skewt  385.491803
46   1  1  3   GARCH   skewt  385.491803
..  .. .. ..     ...     ...         ...
114  2  0  4   GARCH  normal  413.718610
35   1  0  3  EGARCH  normal  414.308609
99   2  0  3  EGARCH  normal  415.158920
51   1  0  4  EGARCH  normal  416.308608
115  2  0  4  EGARCH  normal  417.158921

'''
# model-1 en dusuk AIC degerli;

modelarch = arch_model(veri["Rassal"],p=1,o=1,q=1,vol="GARCH",dist="skewt",mean="Zero").fit(disp="off")
# print(modelarch)
# ortalamasi zaten sifir

# arch etkisi kontrol 
h = het_arch(modelarch.std_resid, nlags=1)[1]
print(h)
# 0.859623524612982 -> H0 kabul arch etkisi yok.

plt.plot(veri["Rassal"])
plt.plot(modelarch.conditional_volatility) # aykiri degerleri ne kadar tahmin edebiliyoruz?

# ### OZET ####
# Mevsimsellik -> Deterministik
# Trend -> Arima ile modellenecek




# ##### Rolling Window - Kayan Yapi
test_sayisi = len(enf_test)
vol_tahmin = [] # volatility olmadigi icin.

for i in range(test_sayisi):
    train = enfay["Enf"][:-(test_sayisi-i)]
    modelarch = arch_model(train, p=1, o=1, q=1, vol="GARCH", dist="skewt", mean="Zero")
    model_arch = modelarch.fit(disp="off")
    tahmin = model_arch.forecast(horizon=1) # horizon -> kaÃ§ adim sonrasini tahmin edecek??
    vol_tahmin.append(np.sqrt(tahmin.variance.values[-1,:][0])) # Array Yapisindan Ã§ikarmak iÃ§in ekstradan [0] parametresi ekledik.



# ## Trend Tahmin - ARIMA
model_trend = auto_arima(veri["Trend"],seasonal=False, trace=False)
tahmin_trend = model_trend.predict(test_sayisi)

tahmin_mev = veri["Mevsimsellik"].iloc[-(test_sayisi):]
# print(tahmin_mev)


# sonuc - toplamsal model
plt.figure()
son = tahmin_trend + tahmin_mev.values
enf_test["Tahmin"] = son

plt.ylim(top=13)
plt.plot(enf_train["Enf"], label = "Train")
plt.plot(enf_test["Enf"], label="Test")
plt.plot(enf_test["Tahmin"], label="Tahmin")
plt.legend()
plt.show()


# Model Belirleme SON
# ARIMA modelimiz volatility degerlerinde biraz zorlaniyor ama genel olarak en iyi accuracye sahip
plt.figure()
son = tahmin_trend + tahmin_mev.values + vol_tahmin
enf_test["Tahmin"] = son
plt.ylim(top=13)
plt.plot(enf_train["Enf"], label = "Train")
plt.plot(enf_test["Enf"], label="Test")
plt.plot(enf_test["Tahmin"], label="Tahmin")
plt.legend()
plt.show()



####### Doviz ve Faiz oranlarinin enflasyona etkisi analizi

# doviz - dolar tl satis uzerinden ornek alindi

dolar = evds.get_data(["TP.DK.USD.A.YTL"], startdate="01-01-2003",enddate="01-02-2025",frequency=5)
dolar.rename(columns={"TP_DK_USD_A_YTL":"Dolar(TL)"},inplace=True)

tarih=pd.date_range("01-01-2003",periods=len(dolar),freq="M") # tarih indekslemek iÃ§in
dolar["Tarih"]=tarih
dolar.set_index("Tarih",inplace=True)

# faiz - (ihtiyac kredisi uzerinden ornek alindi)
# faiz verisi: https://evds2.tcmb.gov.tr/index.php?/evds/portlet/K24NEG9DQ1s%3D/tr
ihtiyackredisi = evds.get_data(["TP.KTF10"], startdate="01-01-2003",enddate="01-02-2025",frequency=5)
ihtiyackredisi.rename(columns={"TP_KTF10":"Kredi(TL)"},inplace=True)

tarih=pd.date_range("01-01-2003",periods=len(ihtiyackredisi),freq="M")
ihtiyackredisi["Tarih"] = tarih
ihtiyackredisi.set_index("Tarih",inplace=True)


train_size = int(len(enf_test) * 0.8)

train = enf_test.iloc[:train_size]
test = enf_test.iloc[train_size:]  

train["Doviz_Kuru"] = dolar["Dolar(TL)"]
train["Faiz_Orani"] = ihtiyackredisi["Kredi(TL)"]


y_train = train["Enf"]  
x_train = pd.DataFrame()
x_train["Doviz_Kuru"] = train["Doviz_Kuru"]   
x_train["Faiz_Orani"] = train["Faiz_Orani"]


y_test = test["Enf"]
x_test = pd.DataFrame()
x_test["Doviz_Kuru"] = train["Doviz_Kuru"] 
x_test["Faiz_Orani"] = train["Faiz_Orani"]


print("y_train boyutu:", len(y_train)) # 28
print("y_test boyutu:", len(y_test)) # 8
print("x_test boyutu:", len(x_test)) # 28 -> 8 reshalepeledik.


x_test = np.array(x_test[:8]).reshape(-1, 1)


model = SARIMAX(y_train, exog=x_train, order=(1, 1, 1), seasonal_order=(1, 1, 1, 12))
results = model.fit()


y_pred = results.predict(start=len(y_train), 
                         end=len(y_train) + len(y_test) - 1, 
                         exog=x_test)

print(results.summary())

plt.figure(figsize=(10, 6))
plt.plot(y_test.index, y_test, label="GerÃ§ek DeÄŸerler", color='blue')  # Actual values
plt.plot(y_test.index, y_pred, label="Tahmin Edilen DeÄŸerler", color='red')  # Predictions
plt.legend()
plt.title("Enflasyon Tahminleri: DÃ¶viz Kuru ve Faiz OranÄ± ile")
plt.xlabel("Tarih")
plt.ylabel("Enflasyon")
plt.show()


'''
Doviz Kuru ve Faizin Enflasyon Ãœzerine Etkisi Yorumlama

Doviz_Kuru (KatsayÄ±: 1.6440, P>|z|: 0.013)
Yorum: DÃ¶viz kurunun enflasyon Ã¼zerindeki etkisi pozitif ve anlamlÄ±

Faiz_Orani (KatsayÄ±: -0.3996, P>|z|: 0.003)
Yorum: Faiz oranÄ±nÄ±n enflasyon Ã¼zerindeki etkisi negatif ve anlamlÄ± 

ar.L1 (KatsayÄ±: 0.9998, P>|z|: 0.044)
Yorum: AR(1) bileÅŸeni pozitif ve anlamlÄ±
Bu, serinin bir Ã¶nceki dÃ¶nemdeki deÄŸerinin mevcut dÃ¶neme etkisinin gÃ¼Ã§lÃ¼ olduÄŸunu gÃ¶steriyor.

ma.L1 (KatsayÄ±: -0.7955, P>|z|: 0.013)
Yorum: MA(1) bileÅŸeni negatif ve anlamlÄ±
Serinin bir Ã¶nceki dÃ¶nemdeki hata teriminin mevcut dÃ¶nemde dÃ¼zeltici bir etkisi olduÄŸunu gÃ¶steriyor

ar.S.L12 ve ma.S.L12
ar.S.L12 (P>âˆ£zâˆ£:0.959) ve ma.S.L12 (P>âˆ£zâˆ£:1.000) anlamlÄ± deÄŸil.
Bu, 12 periyotluk (yÄ±llÄ±k) mevsimsel yapÄ±nÄ±n modelde etkili olmadÄ±ÄŸÄ±nÄ± gÃ¶steriyor. Mevsimsel bileÅŸenler modelden Ã§Ä±karÄ±labilir.

Hata Terimi ve Modelin Ä°statistiksel Ã–zellikleri

sigma2 (0.0854)
Modelin hata terimlerinin varyansÄ± Ã§ok kÃ¼Ã§Ã¼k ve anlamlÄ± deÄŸil ( ğ‘ = 0.997 )
bu da modelin tahmin edilen varyansÄ± dÃ¼ÅŸÃ¼k bulduÄŸunu gÃ¶steriyor.

Ljung-Box Testi (Q): Prob(Q) = 0.78
Hata terimlerinde anlamlÄ± bir otokorelasyon yok. Bu, modelin artÄ±klarÄ±n baÄŸÄ±msÄ±z olduÄŸunu gÃ¶steriyor ve modelin uygunluÄŸunu destekliyor.

Jarque-Bera Testi: Prob(JB) = 0.49
Hata terimlerinin normal daÄŸÄ±lÄ±ma uygun olduÄŸu sonucuna varÄ±lÄ±yor (ğ‘ > 0.05)

Heteroskedasticity Test (H): Prob(H) = 0.31
Hata terimlerinde heteroskedastisite yok (ğ‘ > 0.05)
Bu, hata terimlerinin sabit varyanslÄ± olduÄŸunu gÃ¶steriyor.

Ozetle:
DÃ¶viz kuru ve faiz oranÄ± enflasyonu anlamlÄ± bir ÅŸekilde etkiliyor.
DÃ¶viz kuru pozitif, faiz oranÄ± negatif bir etkiye sahip.

Model PerformansÄ±
Mevsimsel bileÅŸenlerin anlamlÄ± olmadÄ±ÄŸÄ± gÃ¶rÃ¼lÃ¼yor, SARIMAX yerine ARIMAX modeli daha uygun olabilir.
Hata terimlerinin baÄŸÄ±msÄ±z ve sabit varyanslÄ± olmasÄ± modelin gÃ¼venilir olduÄŸunu gÃ¶steriyor.

'''

# Mevsimsel bileÅŸenler olmadan ARIMAX modeli kurarsak
model = SARIMAX(y_train, exog=x_train, order=(1, 1, 1))  # Mevsimsel bileÅŸenleri cikardik
results = model.fit()

y_pred = results.predict(start=len(y_train), 
                         end=len(y_train) + len(y_test) - 1, 
                         exog=x_test)

# Performans metrikleri
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
mae = mean_absolute_error(y_test, y_pred)

print("RMSE (Mevsimsel Olmadan):", rmse)
print("MAE (Mevsimsel Olmadan):", mae)


plt.figure(figsize=(10, 6))
plt.plot(y_test.index, y_test, label="GerÃ§ek DeÄŸerler", color='blue')
plt.plot(y_test.index, y_pred, label="Tahmin Edilen DeÄŸerler", color='red')
plt.legend()
plt.title("Enflasyon Tahminleri: DÃ¶viz Kuru ve Faiz OranÄ± ile (Mevsimsellik Olmadan)")
plt.xlabel("Tarih")
plt.ylabel("Enflasyon")
plt.show()

# Model Ã–zeti
print(results.summary())

'''
Doviz_Kuru (KatsayÄ±: 1.3092, P>|z|: 0.054)
DÃ¶viz kurunun enflasyon Ã¼zerindeki etkisi artÄ±k p-deÄŸeri 0.05 eÅŸiÄŸine Ã§ok yakÄ±n, ancak tam anlamlÄ±lÄ±k saÄŸlayamamÄ±ÅŸ (p = 0.054)

Faiz_Orani (KatsayÄ±: -0.3149, P>|z|: 0.310)
Faiz oranÄ±nÄ±n enflasyon Ã¼zerindeki etkisi anlamlÄ± deÄŸil (p = 0.310).

ar.L1 ve ma.L1 (P>|z|: 0.944 ve 0.957)
Otoregresif (AR) ve hareketli ortalama (MA) bileÅŸenlerinin katsayÄ±larÄ± anlamlÄ± deÄŸil. Modelimizin geÃ§miÅŸ deÄŸerleri ve hata terimleri ile enflasyon arasÄ±ndaki iliÅŸkiyi anlamlÄ± bir ÅŸekilde kullanamadÄ±ÄŸÄ±nÄ± gÃ¶steriyor.

sigma2 (6.2026, P>|z|: 0.000)
Hata terimlerinin varyansÄ± anlamlÄ± ( p < 0.05).

AIC ve BIC (AIC: 135.937, BIC: 142.417) bir Ã¶nceki modele gÃ¶re fazla Ã§Ä±ktÄ±. 

Ljung-Box Testi (Q: 0.77, Prob(Q): 0.38)
Hata terimlerinde otokorelasyon bulunmuyor ( p > 0.05).

Jarque-Bera Testi (JB: 1.94, Prob(JB): 0.38)
Hata terimlerinin normal daÄŸÄ±lÄ±ma uygun olduÄŸu gÃ¶rÃ¼lÃ¼yor (p>0.05).

Heteroskedasticity Test (H: 0.38, Prob(H): 0.16)
Hata terimlerinde heteroskedastisite bulunmuyor. Bu, modelin sabit varyansa sahip olduÄŸunu destekliyor.


Ozetle:

Mevsimsel bileÅŸenleri Ã§Ä±kararak model performansÄ±nda bir iyileÅŸme saÄŸlanmadÄ±
KatsayÄ±larÄ±n anlamlÄ±lÄ±k seviyeleri dÃ¼ÅŸmÃ¼ÅŸ, Ã¶zellikle faiz oranÄ± iÃ§in anlamlÄ±lÄ±k tamamen kaybedildi
Bu model daha basarisiz oldu.

Volatility'i daha iyi aciklayan GARCH modeli ile deneyelim
'''

# sarimaxtaki artiklari alalim
residuals = results.resid

garch_model = arch_model(residuals, vol='Garch', p=1, q=1, dist='normal')
garch_results = garch_model.fit()

print(garch_results.summary())

volatility = garch_results.conditional_volatility

plt.figure(figsize=(10, 6))
plt.plot(volatility, label='Volatilite')
plt.title("Tahmin Edilen Volatilite")
plt.legend()
plt.show()

'''
Garch Modeli Ozeti

Mean Model (Ortalama Modeli):

mu (Ortalama KatsayÄ±sÄ±): âˆ’0.6211,  P>âˆ£tâˆ£=0.138
Ortalama katsayÄ±sÄ± anlamlÄ± deÄŸil (p>0.05)
Bu, modelin deÄŸiÅŸkenlerin ortalama etrafÄ±nda gÃ¼Ã§lÃ¼ bir iliÅŸki kuramadÄ±ÄŸÄ±nÄ± gÃ¶steriyor.


Volatility Model
omega (Sabit Terim): 6.1103eâˆ’08, P>âˆ£tâˆ£=1.000
Sabit terim anlamlÄ± deÄŸil (p>0.05). Bu, volatilitenin temel seviyesinin modele katkÄ±sÄ±nÄ±n Ã§ok dÃ¼ÅŸÃ¼k olduÄŸunu gÃ¶sterir.

alpha[1] (ARCH KatsayÄ±sÄ±): 8.7153eâˆ’13, P>âˆ£tâˆ£=1.000
Ã–nceki hata terimlerinin karesinin mevcut volatilite Ã¼zerindeki etkisi anlamlÄ± deÄŸil (p>0.05).


beta[1] (GARCH KatsayÄ±sÄ±): 0.9661, P>âˆ£tâˆ£=2.692eâˆ’06
Yorum: GARCH bileÅŸeni oldukÃ§a anlamlÄ± (p<0.05). 
Bu, Ã¶nceki dÃ¶nem volatilitesinin mevcut volatiliteyi gÃ¼Ã§lÃ¼ bir ÅŸekilde etkilediÄŸini gÃ¶steriyor.


Model PerformansÄ±
AIC: 135.422 ve BIC: 140.751

Mevsimsel SARIMAX modelindeki AIC (74) ve BIC (79) deÄŸerleriyle karÅŸÄ±laÅŸtÄ±rÄ±ldÄ±ÄŸÄ±nda bu deÄŸerler oldukÃ§a yÃ¼ksek. Bu durum, GARCH modelinin tahmin doÄŸruluÄŸunun dÃ¼ÅŸÃ¼k olduÄŸunu gÃ¶steriyor.

Log-Likelihood: -63.7111
Modelin veriyle uyumunu ifade eder. Daha yÃ¼ksek log-likelihood, daha iyi uyum anlamÄ±na gelir. Ancak burada dÃ¼ÅŸÃ¼k bir uyum gÃ¶zleniyor.

'''


